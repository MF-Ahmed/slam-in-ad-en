% !Mode:: "TeX:UTF-8"
\thispagestyle{empty}

\chapter{Review of Basic Mathematical Concepts}
\label{sec:math-basics}
\thispagestyle{empty}

Before delving into various sensor processing methods, let's review some fundamental mathematical concepts. This book largely follows the notation conventions established in ``Introduction to Visual SLAM''\cite{Gao2017}. To avoid redundancy, we must assume that readers are already familiar with the basic geometric knowledge presented in that book. This book does not elaborate on processes such as quaternion-to-rotation-matrix transformations in detail; instead, it briefly mentions their conclusions for readers to refer back to at any time. For topics not extensively covered in \cite{Gao2017}, this chapter provides additional explanations and derivations as appropriate.

\newpage
\includepdf[width=\textwidth]{art/ch2.pdf}

%\pagestyle{main}
\section{Geometry}
\subsection{Coordinate Systems}

To describe the position and orientation of an autonomous vehicle, we should first define various coordinate systems for it. Firstly, we assume the existence of a fixed coordinate system in the world, known as the \textbf{world coordinate system} or \textbf{inertial coordinate system}. There are several ways to define this coordinate system in the real world, but in principle, it can be simply considered as a fixed coordinate system. When the vehicle moves in the world coordinate system, there exists a transformation relationship between the vehicle's own coordinate system (referred to as the \textbf{body coordinate system} or \textbf{body frame}) and the world system. This transformation relationship changes over time, allowing us to define the vehicle's \textbf{linear velocity}, \textbf{angular velocity}, \textbf{acceleration}, and other physical quantities. This constitutes the motion process of the vehicle.

However, explaining what linear velocity, angular velocity, and especially attitude mean from a mathematical perspective is not so intuitive. The attitude of the vehicle is usually described by a \textbf{rotation matrix} or \textbf{quaternion}. When they change over time, how many-dimensional vectors should be used to describe the angular velocity? How does the angular velocity vector act on the rotation matrix or quaternion? Are there any formal differences in their various definitions? Are they essentially the same? These are the questions this chapter aims to answer.

A three-dimensional coordinate system is composed of three vectors in space. Typically, we choose a set of unit orthogonal vectors to form a reference frame. For instance, if $(\mathbf{e}_1, \mathbf{e}_2, \mathbf{e}_3)$ are the three vectors of the world coordinate system, it means that these three vectors have a length of 1 and their inner products are 0. In this case, we say that a coordinate system (reference frame) $E={\mathbf{e}_1, \mathbf{e}_2, \mathbf{e}_3}$ has been chosen. Then, any three-dimensional spatial vector $\mathbf{a}$ can be represented in this reference frame as:
\begin{equation}
	\mathbf{a} = a_1 \mathbf{e}_1 + a_2 \mathbf{e}_2 + a_3\mathbf{e}_3,
\end{equation}
where $(a_1, a_2, a_3)$ are the coordinates of the vector $\mathbf{a}$.

Please note that even without specifying a reference frame and coordinates, various operations can be performed between vectors. For example, the following operations can be performed between two vectors $\mathbf{a}$ and $\mathbf{b}$:

\begin{enumerate}
	\item \textbf{Addition and subtraction}. The result of vector addition or subtraction is still a vector, following the parallelogram rule:
	\begin{equation}
		\mathbf{c} = \mathbf{a} \pm \mathbf{b}.
	\end{equation}
	If the vectors have coordinates, the components are simply added or subtracted.
	
	\item \textbf{Scalar multiplication}. Multiplying a vector by any scalar $k\in \mathbb{R}$ scales the vector:
	\begin{equation}
		\mathbf{b} = k \mathbf{a},
	\end{equation}
	resulting in another vector. When $\mathbf{a}$ has coordinates, these coordinates are scaled accordingly.
	
	\item \textbf{Taking the length}. We can compute the length of a vector, denoted as:
	\begin{equation}
		\| \mathbf{a} \|.
	\end{equation}
	The length yields a scalar value. Mathematically, a vector's length can be zero or negative, for instance, in Minkowski space, but in the physical world of autonomous driving, we are concerned with vectors in Euclidean space, where their length is always non-negative.
	
	\item \textbf{Dot product}. The dot product of two vectors yields the product of their lengths times the cosine of the angle between them, resulting in a scalar:
	\begin{equation}
		\mathbf{a} \cdot \mathbf{b} = \|\mathbf{a} \| \|\mathbf{b} \| \cos \left\langle\mathbf{a},\mathbf{b} \right\rangle,
	\end{equation}
	where if vectors have coordinates, the dot product results from the sum of the products of their respective components.
	
	\item \textbf{Cross product}. The cross product of two vectors is another vector whose direction is perpendicular to the plane formed by the two vectors, and its magnitude is the product of their lengths times the sine of the angle between them. If vectors $\mathbf{a},\mathbf{b}$ are defined in the $\mathbf{e}_1, \mathbf{e}_2, \mathbf{e}_3$ frame, the cross product is written as:
	\begin{equation}
		\mathbf{a} \times \mathbf{b} = \left\| {\begin{array}{*{20}{c}}
				\mathbf{e}_1 & \mathbf{e}_2 & \mathbf{e}_3 \\
				{{a_1}}&{{a_2}}&{{a_3}}\\
				{{b_1}}&{{b_2}}&{{b_3}}
		\end{array}} \right\| = \left[ \begin{array}{l}
			{a_2}{b_3} - {a_3}{b_2}\\
			{a_3}{b_1} - {a_1}{b_3}\\
			{a_1}{b_2} - {a_2}{b_1}
		\end{array} \right] = \left[ {\begin{array}{*{20}{c}}
				0&{ - {a_3}}&{{a_2}}\\
				{{a_3}}&0&{ - {a_1}}\\
				{ - {a_2}}&{{a_1}}&0
		\end{array}} \right] \mathbf{b} \buildrel \Delta \over = { \mathbf{a}^ \wedge } \mathbf{b}.
	\end{equation}
	
	The cross product can also be expressed as the usual matrix-vector multiplication, which requires expressing the first vector in a \textbf{skew-symmetric} matrix form\footnote{A skew-symmetric matrix satisfies $\mathbf{A}^\top = -\mathbf{A}$.}. We use the $^\wedge$ symbol to define this transformation:
	\begin{equation}
		\mathbf{a}^\wedge = \left[ {\begin{array}{*{20}{c}}
				0&{ - {a_3}}&{{a_2}}\\
				{{a_3}}&0&{ - {a_1}}\\
				{ - {a_2}}&{{a_1}}&0
		\end{array}} \right] = \mathbf{A}.
	\end{equation}
		
	Note that this operator is a \textbf{one-one mapping}, meaning that for any vector, there exists a unique corresponding skew-symmetric matrix, and vice versa. We use the $^\vee$ symbol to denote the mapping from skew-symmetric matrix to vector:
	\begin{equation}
		\mathbf{A}^\vee = \mathbf{a}.
	\end{equation}
	
	The skew-symmetric matrix operator is a symbol widely used in the subsequent text; readers should pay attention to this notation. In other literature, it might also be denoted as $\mathbf{a}_\times, \mathbf{a}^\times, [\mathbf{a}]_\times, \hat{\mathbf{a}}$\cite{Qin2018}, all of which have the same meaning. This book uniformly adopts the $\wedge$ and $\vee$ symbols on the upper right, as they appear more concise.
\end{enumerate}
	
Lastly, even when a reference frame is not specified, vectors can undergo the aforementioned operations. Their results are independent of the choice of reference frame. If a reference frame and coordinates are specified, then the aforementioned computations can also be represented using numerical values of coordinates.

\begin{figure}[!htp]
	\centering
	\includegraphics[width=0.7\textwidth]{math-basics/coordinate-system.pdf}
	\caption{The body and world coordinate systems of a typical autonomous vehicle sensors}
	\label{fig:corrdinate-system}
\end{figure}

An autonomous vehicle is equipped with various types of sensors. We typically assume that each sensor has its own reference frame, and their respective axis directions are defined according to the usage habits of each sensor. For example, in Figure~\ref{fig:corrdinate-system}, the IMU, 64-line lidar, and camera of the vehicle all define their own reference frames. The vehicle body generally uses the \textbf{front-left-up}\footnote{The convention "front-left-up" refers to the $X$ axis pointing forward, the $Y$ axis pointing left, and the $Z$ axis pointing up, following the right-hand rule. The convention for "right-front-up" is analogous.} or \textbf{right-front-up} order to define its coordinate system, while the camera coordinate system commonly adopts the \textbf{right-down-front} order. Consequently, there exist rotation and translation relationships between the coordinate systems of various sensors, which we characterize using rotation matrices and translation vectors.

Assuming a point $\mathbf{p}$ in the world coordinate system has coordinates $\mathbf{p}_w$, and its coordinates in the vehicle body coordinate system are $\mathbf{p}_b$, then we define the rotation matrix $\mathbf{R}_{wb}$ and the translation vector $\mathbf{t}_{wb}$, such that:

\begin{equation}
	\mathbf{p}_w = \mathbf{R}_{wb} \mathbf{p}_b + \mathbf{t}_{wb},
\end{equation}

It is crucial for readers to understand the approach here. The key points are as follows:
\begin{enumerate}
	\item Firstly, we define the transformation relationship between \textbf{coordinates}. $\mathbf{R}_{wb}$ and $\mathbf{t}_{wb}$ are used to handle coordinate transformations between vectors. Some materials deal with transformations between \textbf{coordinate axes} (or bases), interpreting rotation and translation as a transformation of a \textbf{coordinate axis} from one position to another. This definition is opposite to that of this book\footnote{One deals with transformations of coordinates, while the other deals with transformations of bases. Readers should be cautious.}, so please be careful.
	\item We can directly write $\mathbf{R}_{wb}, \mathbf{t}_{wb}$ as a \textbf{transformation matrix} $\mathbf{T}_{wb}$, expressing coordinate transformations in homogeneous form:
	\begin{equation}
		\mathbf{p}_w = \mathbf{T}_{wb} \mathbf{p}_{b}.
	\end{equation}
	This transforms the discussion into properties of the transformation matrix $\mathbf{T}$. The specific form of $\mathbf{T}$ is:
	\begin{equation}
		\mathbf{T}_{wb} = \begin{bmatrix}
			\mathbf{R}_{wb} & \mathbf{t}_{wb} \\
			\mathbf{0} & 1
		\end{bmatrix} \in \mathbb{R}^{4 \times 4}.
	\end{equation}s
	However, since the subsequent discussion will involve the IMU, which does not directly measure the differential of $\mathbf{T}$, we prefer to separate $\mathbf{R}$ and $\mathbf{t}$ rather than express them in the form of a transformation matrix.
	\item Our subscript reading order is \textbf{from right to left}, meaning the subscript $wb$ is right-multiplied with $b$ to obtain variables in the $w$ system. This makes writing and reading more fluid and intuitive. Different books handle the superscript and subscript of coordinate systems differently. Some write them on the left, some write them above, and some books even have four different markings (superscript, subscript, left, right) for one variable. This book uniformly uses the subscript $wb$ to define various variables. Since all variables have the subscript $wb$, we omit these subscripts in the vast majority of content to strive for simplicity. We also need to discuss various variables at different times or iteration numbers, which will introduce subscripts related to time or iteration numbers. If combined with coordinate system subscripts, readers would have to face a large number of formulas with various superscripts and subscripts.
\end{enumerate}

All three-dimensional rotation matrices form the \textbf{Special Orthogonal Group} ($\mathrm{SO}(3)$). It is a $3 \times 3$ real matrix that satisfies:
\begin{itemize}
	\item The rotation matrix is an orthogonal matrix: $\mathbf{R}^\top = \mathbf{R}^{-1}$.
	\item The determinant of the rotation matrix is 1: $\det(\mathbf{R}) = 1$.
\end{itemize}

Additionally, a rotation matrix can also be represented by \textbf{quaternions} or \textbf{rotation vectors}. Below, we will review their definitions and conversion relationships.

\subsection{Rotation Vectors}
Rotation vectors, also known as \textbf{angle-axis}, correspond to the Lie algebra $\mathfrak{so}(3)$ of $\mathrm{SO}(3)$. Since $\mathfrak{so}(3)$ is the tangent space of $\mathrm{SO}(3)$, as we will see later, rotation vectors can also be used to express angular velocities.

Let's denote a rotation vector as $\mathbf{w} \in \mathbb{R}^3$, and it can be decomposed into direction and magnitude: $\mathbf{w}=\theta \mathbf{n}$. The conversion relationship from rotation vector to rotation matrix can be described by \textbf{Rodrigues' formula} or the exponential map on $\mathrm{SO}(3)$:

\begin{equation}
	\label{eq:rogridues}
	\mathbf{R} = \cos \theta \mathbf{I} + \left( {1 - \cos \theta } \right) \mathbf{n}{\mathbf{n}^\top} + \sin \theta 
	{ \mathbf{n}^ \wedge } = \exp(\mathbf{w}^\wedge).
\end{equation}

Here, $\exp$ can also be expanded using Taylor series and simplified to the formula on the left. To simplify notation, we denote the uppercase $\mathrm{Exp}$ as:

\begin{equation}
	\mathrm{Exp}(\mathbf{w}) = \exp(\mathbf{w}^\wedge),
\end{equation}
which eliminates one $^\wedge$ symbol, making the formula appear more concise in complex expressions.

Conversely, the conversion relationship from rotation matrix to rotation vector can be described by the logarithmic map:

\begin{equation}
	\mathbf{w} = \log (\mathbf{R}) ^ \vee = \mathrm{Log}(\mathbf{R}).
\end{equation}

The computation method for the angle-axis is as follows. For the angle $\theta$, we have:

\begin{equation}
	\label{eq:R2theta}
	\theta = \arccos \left( \frac{\mathrm{tr}(\mathbf{R}) - 1}{2} \right).
\end{equation}

And the axis $\mathbf{n}$ is the unit eigenvector of $\mathbf{R}$ corresponding to the eigenvalue 1:

\begin{equation}
	\label{eq:R2n}
	\mathbf{R} \mathbf{n} = \mathbf{n}.	
\end{equation}

\subsection{Quaternions}
Three-dimensional rotations can also be described by unit quaternions. Quaternions, also known as expanded complex numbers, consist of a real part and three imaginary parts. This book uses Hamiltonian quaternions\footnote{According to different tastes, there are slight variations in the definition of quaternions. Hamiltonian is the most common and intuitive way of defining quaternions.}, defined as:

\begin{equation}
	\mathbf{q} = q_0 + q_1 i + q_2 j + q_3 k,
\end{equation}

where $q_0$ is the real part, and $q_1, q_2, q_3$ are the imaginary parts. The imaginary units $i, j, k$ satisfy the following multiplication rules:

\begin{equation}
	\label{eq:quaternionVirtual}
	\left\{ \begin{array}{l}
		{i^2} = {j^2} = {k^2} =  - 1\\
		ij = k,ji =  - k\\
		jk = i,kj =  - i\\
		ki = j,ik =  - j
	\end{array} \right. .
\end{equation}

To simplify notation, the three imaginary parts can be represented as a vector, and the quaternion can be expressed as a combination of scalar part $s$ and vector part $\mathbf{v}$:

\begin{equation}
	\mathbf{q} = [s, \mathbf{v}]^\top.
\end{equation}

Using the vector part, a compact form of quaternion multiplication can be written.

Following the multiplication rules of quaternions, several commonly used quaternion calculation methods can be derived. We list them below.
\begin{enumerate}
	\item \emph{Addition and Subtraction}
	
	The addition and subtraction of quaternions $\mathbf{q}_a$ and $\mathbf{q}_b$ are given by:
	\begin{equation} 	
		\mathbf{q}_a \pm \mathbf{q}_b = \left[ s_a \pm s_b, \mathbf{v}_a \pm \mathbf{v}_b \right]^\top.
	\end{equation}
	
	\item \emph{Multiplication}
	
	Multiplication involves multiplying each term of $\mathbf{q}_a$ by each term of $\mathbf{q}_b$ and then summing them up, while following the rules defined by Equation \eqref{eq:quaternionVirtual}. It can be expressed as:
	\begin{equation}
		\begin{aligned}
			\mathbf{q}_a \mathbf{q}_b &= {s_a}{s_b} - {x_a}{x_b} - {y_a}{y_b} - {z_a}{z_b}\\
			&+ \left( {{s_a}{x_b} + {x_a}{s_b} + {y_a}{z_b} - {z_a}{y_b}} \right)i\\
			&+ \left( {{s_a}{y_b} - {x_a}{z_b} + {y_a}{s_b} + {z_a}{x_b}} \right)j\\
			&+ \left( {{s_a}{z_b} + {x_a}{y_b} - {y_a}{x_b} + {z_a}{s_b}} \right)k.
		\end{aligned}
	\end{equation}
	
	Though slightly complex, this form is well-structured. Expressing it in vector form and using inner and outer product operations results in a more concise expression:
	\begin{equation}
		\mathbf{q}_a \mathbf{q}_b = \left[ s_a s_b - \mathbf{v}_a^\top \mathbf{v}_b, s_a\mathbf{v}_b + s_b\mathbf{v}_a 
		+ \mathbf{v}_a \times \mathbf{v}_b \right]^\top.
	\end{equation}
	
	Under this definition of multiplication, the product of two real quaternions is still real, which is consistent with complex numbers. However, note that quaternion multiplication is usually non-commutative due to the presence of the cross-product term, unless $\mathbf{v}_a$ and $\mathbf{v}_b$ are collinear in $\mathbb{R}^3$, in which case the cross-product term becomes zero.
	
	This book does not deliberately distinguish between standard multiplication and quaternion multiplication. Some materials may use symbols such as $\otimes$ to differentiate quaternion multiplication, but this book consistently uses standard multiplication. Quaternions are not multiplied with ordinary vectors or matrices, so **the meaning of multiplication should be clear**.
	
	\item \emph{Norm}
	
	The norm of a quaternion is defined as:
	\begin{equation}
		\| \mathbf{q}_a \| = \sqrt{ s_a^2 + x_a^2 + y_a^2 + z_a^2 }.
	\end{equation}
	It can be verified that the norm of the product of two quaternions equals the product of their norms, which ensures that the product of unit quaternions remains a unit quaternion:
	\begin{equation}
		\| \mathbf{q}_a \mathbf{q}_b \| = \|\mathbf{q}_a \| \| \mathbf{q}_b \|.
	\end{equation}
	
	\item \emph{Conjugate}
	
	The conjugate of a quaternion is obtained by negating the imaginary parts:
	\begin{equation}
		\mathbf{q}_a^* = s_a - x_ai - y_aj - z_ak = [s_a, -\mathbf{v}_a]^\top.
	\end{equation}
	Multiplying a quaternion by its conjugate yields a real quaternion with a real part equal to the square of its norm:
	\begin{equation}
		\mathbf{q}^* \mathbf{q} = \mathbf{q} \mathbf{q}^* = [s^2+\mathbf{v}^\top \mathbf{v}, \mathbf{0} ]^\top.
	\end{equation}
	
	\item \emph{Inverse}
	
	The inverse of a quaternion is given by:
	\begin{equation}
		\label{eq:quaternionInverse}
		\mathbf{q}^{-1} = \mathbf{q}^* / \| \mathbf{q} \| ^2.
	\end{equation}
	According to this definition, the product of a quaternion and its inverse yields a real quaternion $\mathbf{1}$:
	\begin{equation}
		\mathbf{q} \mathbf{q}^{-1} = \mathbf{q}^{-1} \mathbf{q} = \mathbf{1}.
	\end{equation}
	
	If $\mathbf{q}$ is a unit quaternion, its inverse and conjugate are the same. Moreover, the inverse of a product obeys a property similar to matrices:
	\begin{equation}
		\left( \mathbf{q}_a \mathbf{q}_b \right)^{-1} = \mathbf{q}_b^{-1} \mathbf{q}_a^{-1}.
	\end{equation}
	
	\item \emph{Scalar Multiplication}
	
	Similar to vectors, quaternions can be multiplied by scalars:
	\begin{equation}
		k \mathbf{q} = \left[ ks, k\mathbf{v} \right]^\top.
	\end{equation}
\end{enumerate}


\subsubsection{Representing Rotation with Quaternions}
Rotation of a point can be expressed using quaternions. Let's assume a three-dimensional point in space $\mathbf{p} = [x,y,z]\in \mathbb{R}^3$, and a rotation specified by a unit quaternion $\mathbf{q}$. The point $\mathbf{p}$ undergoes a rotation to become $\mathbf{p}'$. If described using matrices, then $\mathbf{p}'=\mathbf{R} \mathbf{p}$. But how can we express this relationship using quaternions?

Firstly, represent the three-dimensional space point using a quaternion:
\begin{equation}
\mathbf{p} = [0, x, y, z]^\top = [0, \mathbf{v}]^\top.
\end{equation}
This is equivalent to associating the three imaginary parts of the quaternion with the three axes in space. Then, the rotated point $\mathbf{p}'$ can be expressed as the following product:
\begin{equation}\label{eq:rotate-with-quaternion}
	\mathbf{p}' = \mathbf{q} \mathbf{p} \mathbf{q}^{-1}.
\end{equation}
Here, the multiplication is quaternion multiplication, resulting in another quaternion. Finally, extract the imaginary part of $\mathbf{p}'$ to obtain the coordinates of the point after rotation. It can be verified that the real part of the computed result is 0, hence it is a pure imaginary quaternion.

\subsubsection{Conversion from Quaternion to Rotation Matrix and Rotation Vector}
Any unit quaternion describes a rotation, which can also be described using a rotation matrix or rotation vector. Now, let's examine the relationship between quaternions and rotation vectors, rotation matrices.

Before diving into that, it's worth mentioning that quaternion multiplication can also be expressed as a form of matrix multiplication. Let $\mathbf{q}=[s,\mathbf{v}]^\top$ be a quaternion. Define the following symbols $^{+}$ and $^{\oplus}$ as follows\cite{Barfoot2011}:
\begin{equation}
	\mathbf{q}^{+}=\left[\begin{array}{cc}
		s&-\mathbf{v}^\top \\
		\mathbf{v}&s\mathbf{I}+\mathbf{v}^{\wedge}
	\end{array}\right],\quad 
	\mathbf{q}^{\oplus}=
	\left[\begin{array}{cc}
		s & -\mathbf{v}^\top \\
		\mathbf{v} & s\mathbf{I}-\mathbf{v}^{\wedge}
	\end{array}\right],
\end{equation}
where these symbols map quaternions into a $4\times 4$ matrix. Thus, quaternion multiplication can be written in matrix form as follows:
\begin{equation}
	\mathbf{q}_1^ + {\mathbf{q}_2} = \left[ {\begin{array}{*{20}{c}}
			s_1&-\mathbf{v}_1^\top\\
			\mathbf{v}_1 & s_1 \mathbf{I} + \mathbf{v}_1^\wedge
	\end{array}} \right]\left[ {\begin{array}{*{20}{c}}
			{{s _2}} \\
			{{\mathbf{v} _2}}
	\end{array}} \right] = \left[ {\begin{array}{*{20}{c}}
			{ - \mathbf{v} _1^\top{\mathbf{v} _2} + {s _1}{s _2}} \\ 
			{{s _1}{\mathbf{v} _2} + {s _2}{\mathbf{v} _1} + \mathbf{v} _1^ \wedge {\mathbf{v} _2}}
	\end{array}} \right] = \mathbf{q}_1 \mathbf{q}_2.
\end{equation}
Similarly, it can be proven that:
\begin{equation}
	\mathbf{q}_1 \mathbf{q}_2 = \mathbf{q}_1^{+} \mathbf{q}_2 = \mathbf{q}_2^{\oplus} \mathbf{q}_1.
\end{equation}

Then, let's consider the problem of rotating a point in space using quaternions. According to the previous discussion, we have:
\begin{equation}\label{eq:quaternion-to-rotation-matrix-derive}
	\begin{split}
		\mathbf{p}' &= \mathbf{q} \mathbf{p} \mathbf{q}^{-1} = \mathbf{q}^+ \mathbf{p}^+ \mathbf{q}^{-1} \\
		&= \mathbf{q}^+ \mathbf{q}^{{-1}^{\oplus}} \mathbf{p}.
	\end{split}
\end{equation}
Substituting the matrices corresponding to the two symbols, we obtain:
\begin{equation}
	{\mathbf{q}^ + }{\left( {{\mathbf{q}^{ - 1}}} \right)^ \oplus } = \left[ \begin{array}{*{20}{c}}
		s&-\mathbf{v}^\top\\
		\mathbf{v}&s\mathbf{I}+\mathbf{v}^\wedge 
	\end{array} \right]\left[\begin{array}{*{20}{c}}
		s&{\mathbf{v} ^\top}\\
		{ - \mathbf{v} }&{s\mathbf{I} + \mathbf{v} ^ \wedge }
	\end{array} \right] = \left[ \begin{array}{*{20}{c}}
		1&\mathbf{0} \\
		\mathbf{0}^\top&\mathbf{v}\mathbf{v}^\top + {s^2} \mathbf{I} + 2s\mathbf{v} ^ \wedge + {(\mathbf{v} ^ 
			\wedge)}^2 
	\end{array} \right].
\end{equation}
Since both $\mathbf{p}'$ and $\mathbf{p}$ are purely imaginary quaternions, the lower right corner of this matrix actually gives the transformation from quaternion to rotation matrix:
\begin{equation}
	\mathbf{R} = \mathbf{v} \mathbf{v}^\top + {s^2} \mathbf{I} + 2s\mathbf{v} ^ \wedge + {(\mathbf{v} ^ \wedge)}^2.
\end{equation}
To obtain the conversion formula from quaternion to rotation vector, take the trace of both sides of the above equation:
\begin{equation}
	\begin{aligned}
		\mathrm{tr}(\mathbf{R}) &= \mathrm{tr}(\mathbf{v}\mathbf{v}^\top) + 3s^2 + 2s \cdot 0 + 
		\mathrm{tr}((\mathbf{v}^\wedge)^2) \\
		&= v_1^2+v_2^2+v_3^2 + 3s^2 - 2(v_1^2+v_2^2+v_3^2) \\
		&= (1-s^2) + 3s^2 -2(1-s^2)\\
		&= 4s^2 -1.
	\end{aligned}
\end{equation}
Also, from Eq.\eqref{eq:R2theta}, we have:
\begin{equation}
	\begin{aligned}
		\theta &= \arccos(\frac{\mathrm{tr}(\mathbf{R})-1}{2}) \\
		&=\arccos(2s^2-1).
	\end{aligned}
\end{equation}
Thus,
\begin{equation}
	\cos \theta =2s^2-1=2 \cos^2 \frac{\theta}{2} -1,
\end{equation}
so:
\begin{equation}
	\theta = 2 \arccos s.
\end{equation}
Regarding the rotation axis, if we substitute $\mathbf{q}$'s imaginary part for $\mathbf{p}$ in Eq.\eqref{eq:quaternion-to-rotation-matrix-derive}, it's easy to see that the vector formed by the imaginary part of $\mathbf{q}$ remains fixed during rotation, constituting the rotation axis. Thus, by normalizing it by its magnitude, we obtain the rotation axis. In summary, the conversion formula from quaternion to rotation vector can be expressed as follows:
\begin{equation}
	\label{eq:rotationVector2Quaternion}
	\begin{cases}
		\theta  = 2\arccos s\\
		{\left[ {{n_x},{n_y},{n_z}} \right]^\top} = \mathbf{v}^\top /{\sin 
			\frac{\theta }{2}}
	\end{cases} .
\end{equation}

Since quaternions require only four values to represent rotation, most programs choose quaternions as the underlying representation for rotations. They may provide interfaces for matrix operations, such as the previously mentioned $\vee$ or $\log$ operations, or interfaces for quaternions, such as retrieving the four components of a quaternion, and so on. When using these programs, we can simply use these matrix interfaces without concerning ourselves with their underlying storage format.

\subsection{Lie Group and Lie Algebra}
Three-dimensional rotations form the three-dimensional rotation group $\mathrm{SO}(3)$, with its corresponding Lie algebra denoted as $\mathfrak{so}(3)$; three-dimensional transformations form the three-dimensional transformation group $\mathrm{SE}(3)$, with its corresponding Lie algebra denoted as $\mathfrak{se}(3)$.

The mapping from Lie algebra elements to Lie group elements is known as the exponential mapping. For $\mathfrak{so}(3)$ to $\mathrm{SO}(3)$, the exponential mapping is given by:
\begin{equation}\label{key}
	\exp(\boldsymbol{\phi}^\wedge) = \mathbf{R},
\end{equation}
where the specific computation is provided by the Rodrigues' formula \eqref{eq:rogridues}. The inverse mapping, known as the logarithm mapping, is denoted as:
\begin{equation}\label{key}
	\boldsymbol{\phi} = \log(\mathbf{R})^\vee,
\end{equation}
with specific computation provided by equations \eqref{eq:R2theta} and \eqref{eq:R2n}.

We mainly utilize the combination of $\mathrm{SO}(3)$ with translation vectors to derive subsequent motion equations, filtering relationships, etc. We omit the introduction of $\mathrm{SE}(3)$ and $\mathfrak{se}(3)$.

\subsection{BCH Linear Approximation on $\mathrm{SO}(3)$}
The Baker-Campbell-Hausdorff (BCH) formula \cite{gilmore1974baker} provides a relationship between the addition of small quantities in the Lie algebra and the multiplication of small quantities in the Lie group, which is widely used for linearization of various functions. Here, we only present the conclusions.

In $\mathrm{SO}(3)$, for a rotation $\mathbf{R}$ (corresponding to the Lie algebra $\boldsymbol{\phi}$), left-multiplying it by a small rotation, denoted as $\Delta \mathbf{R}$, with the corresponding Lie algebra $\Delta \boldsymbol{\phi}$, results in $ \Delta \mathbf{R} \cdot \mathbf{R}$ on the Lie group. According to the BCH approximation, in the Lie algebra, it is $\mathbf{J}_l^{-1} (\boldsymbol{\phi}) \Delta \boldsymbol{\phi} + \boldsymbol{\phi}$. Thus, we can simply write:
\begin{equation}
	\exp \left( {\Delta { \boldsymbol{\phi} ^ \wedge }} \right)\exp \left( {{ \boldsymbol{\phi} ^ \wedge }} 
	\right) = \exp \left( {{{\left( { \boldsymbol{\phi}  + \mathbf{J}_l^{ - 1}\left( \boldsymbol{\phi}  \right)\Delta 
					\boldsymbol{\phi} } \right)}^ \wedge }} \right).
\end{equation}

Conversely, if we perform addition in the Lie algebra, adding $\Delta \boldsymbol{\phi}$ to $\boldsymbol{\phi}$, it can be approximated as multiplication with left and right Jacobians on the Lie group:
\begin{equation}
	\exp \left( {{{\left( { \boldsymbol{\phi}  + \Delta \boldsymbol{\phi} } \right)}^ \wedge }} \right) = \exp 
	\left( {{{\left( {{ \mathbf{J}_l} (\boldsymbol{\phi})\Delta \boldsymbol{\phi} } \right)}^ \wedge }} \right)\exp \left( {{ 
			\boldsymbol{\phi} ^ \wedge }} \right) = \exp \left( {{\boldsymbol{\phi} ^ \wedge }} \right)\exp \left( 
	{{{\left( {{\mathbf{J}_r}(\boldsymbol{\phi}) \Delta \boldsymbol{\phi} } \right)}^ \wedge }} \right).
\end{equation}

Where the left Jacobian for $\mathrm{SO}(3)$ is given by:
\begin{align}
	\mathbf{J}_l (\theta \mathbf{a}) &= \frac{\sin \theta}{\theta} \mathbf{I} + (1-\frac{\sin \theta }{\theta}) \mathbf{a} \mathbf{a}^\top + \frac{1-\cos \theta}{\theta} \mathbf{a}^\wedge \\
	\mathbf{J}_l^{ - 1}(\theta \mathbf{a}) &= \frac{\theta }{2}\cot \frac{\theta }{2} \mathbf{I} + \left( {1 - \frac{\theta 
		}{2}\cot \frac{\theta }{2}} \right) \mathbf{a} {\mathbf{a}^\top} - \frac{\theta }{2}{ \mathbf{a}^ \wedge }. 
\end{align}
And the right Jacobian for $\mathrm{SO}(3)$ is:
\begin{equation}
	\mathbf{J}_r(\boldsymbol{\phi}) =\mathbf{J}_l(-\boldsymbol{\phi}) .
\end{equation}

Since the Lie algebra $\boldsymbol{\phi}$ and $\mathbf{R}$ can be easily associated, sometimes we also simply denote $\mathbf{J}_r(\boldsymbol{\phi})$ as $\mathbf{J}_r(\mathbf{R})$ instead of $\mathbf{J}_r(\mathrm{Log}(\mathbf{R}))$. This can make the formulas look more concise. In many cases, we also omit the part inside the parentheses of $\mathbf{J}_r(\boldsymbol{\phi})$ and directly write $\mathbf{J}_r$ and $\mathbf{J}_l$.

All of the above content has been introduced in \cite{Gao2017} already. If readers are interested in their detailed derivation process, please check \cite{Gao2017}, \cite{Barfoot2016} or \cite{Sola2017}. This book will directly use the conclusions introduced above.

\section{Kinematics}
Now let's consider a three-dimensional object in motion over time. In this section, we will explore various perspectives on expressing three-dimensional kinematics, which will be correlated with subsequent chapters. Examining three-dimensional kinematics will lead to a series of interesting discussions. Join us as we delve into it.

\subsection{Kinematics from the Perspective of Lie Groups}
\label{sec:so3-kinematics}
Earlier, we discussed how the rotation and translation of an object can be described by $\mathbf{R}$ and $\mathbf{t}$, respectively (here, we omit the subscript $wb$ denoting the coordinate frame). When they vary continuously with time, they become functions of time, $\mathbf{R}(t)$ and $\mathbf{t}(t)$. Obviously, the translational part is trivial, just a function with the codomain $\mathbb{R}^3$. Therefore, we focus on the rotational part.

Let's assume that $\mathbf{R}$ varies with time, i.e., $\mathbf{R}(t)$. According to the property of $\mathbf{R}$ being an orthogonal matrix:
\begin{equation}\label{key}
	\mathbf{R}^\top \mathbf{R} = \mathbf{I},
\end{equation}
it is not difficult to observe:
\begin{equation}
	\frac{\mathrm{d}}{{\mathrm{d}t}}\left( {{\mathbf{R}^\top} \mathbf{R}} \right) = {\dot{\mathbf{R}}^\top} \mathbf{R} 
	+ {\mathbf{R}^\top}\dot{\mathbf{R}} = \mathbf{0},
\end{equation}
which implies:
\begin{equation}
	{\mathbf{R}^\top}\dot{\mathbf{R}} = -({\mathbf{R}^\top}\dot{\mathbf{R}})^\top.
\end{equation}
It can be seen that ${\mathbf{R}^\top}\dot{\mathbf{R}}$ is a skew-symmetric matrix, and a skew-symmetric matrix can be expressed in vector form using the skew-symmetric symbol $^\wedge$. Let's take $\boldsymbol{\omega}^\wedge \in \mathbb{R}^{3 \times 3} = 
{\mathbf{R}^\top}\dot{\mathbf{R}}$, then we can write $\mathbf{R}$ in the form of a differential equation:

\begin{equation}\label{eq:2.51}
	\dot{\mathbf{R}} = \mathbf{R} \boldsymbol{\omega}^\wedge.
\end{equation}

This equation is also known as the \textbf{Poisson equation}\cite{Rauch1965}. It's worth noting that we could also start from $\mathbf{R} \mathbf{R}^\top = \mathbf{I}$, define $\boldsymbol{\omega}^\wedge = \dot{\mathbf{R}} \mathbf{R}^\top$, and obtain the result $\dot{\mathbf{R}} = \boldsymbol{\omega}^\wedge\mathbf{R}$. These two forms are essentially equivalent, just different in appearance.

If we only consider instantaneous changes, then at a fixed time $t$, $\boldsymbol{\omega}$ can be considered constant. In physical terms, we call $\boldsymbol{\omega}$ the \textbf{instantaneous angular velocity}. Given an initial rotation matrix $\mathbf{R}(t_0)$ at time $t_0$, the solution to the above differential equation is:
\begin{equation}\label{eq:2.52}
	\mathbf{R}(t) = \mathbf{R}(t_0) \exp(\boldsymbol{\omega}^\wedge (t-t_0)).
\end{equation}

If readers are familiar with the knowledge of Lie groups and Lie algebras, it's easy to recognize that Equation \eqref{eq:2.52} represents the exponential mapping on $\mathrm{SO}(3)$. Let $\Delta t = t - t_0$, then this equation can also be written as:
\begin{equation}\label{eq:2.53}
	\mathbf{R}(t) = \mathbf{R}(t_0) \mathrm{Exp}(\boldsymbol{\omega} \Delta t).
\end{equation}

From another perspective, we can also expand $\mathbf{R}(t)$ around time $t_0$ using Taylor series, and the first-order approximation is:
\begin{equation}\label{eq:2.54}
	\begin{array}{ll}
		\mathbf{R}(t_0 + \Delta t) &\approx \mathbf{R}(t_0) + \dot{\mathbf{R}}(t_0) \Delta t  \\
		& = \mathbf{R}(t_0) + \mathbf{R}(t_0) \boldsymbol{\omega}^\wedge \Delta t \\ 
		& = \mathbf{R}(t_0)(\mathbf{I} + \boldsymbol{\omega}^\wedge \Delta t).
	\end{array}
\end{equation}

This reveals the approximate form of the exponential mapping:
\begin{equation}
	\mathrm{Exp}( \boldsymbol{\omega} \Delta t) = \mathbf{I} + \boldsymbol{\omega}^\wedge \Delta t+ 
	\frac{1}{2}(\boldsymbol{\omega} ^\wedge \Delta t)^2 + \ldots
\end{equation}

By comparing the above equations, we can see that:
\begin{enumerate}
	\item Equation \eqref{eq:2.53} is the discrete-time form of Equation \eqref{eq:2.52}.
	\item Equation \eqref{eq:2.54} is the linear approximation of Equation \eqref{eq:2.53}.
\end{enumerate}

These two sets of equations are very useful in dealing with angular velocities, and we will continue to use them in the subsequent discussion.

\subsection{Kinematics from the Perspective of Quaternions}

Now let's examine how the kinematic equations change if we use quaternions to represent rotations. This is an alternative description of the same problem from a different perspective. Investigating this issue can help us establish connections between different mathematical representations. We know that the rotation of a vector by quaternions should take the form given by Equation \eqref{eq:quaternion-to-rotation-matrix-derive}, and quaternions themselves carry the unit constraint $\mathbf{q}\mathbf{q}^*=\mathbf{q}^*\mathbf{q} = \mathbf{1}$. Similar to the case of $\mathrm{SO}(3)$, starting from $\mathbf{q}^* 
\mathbf{q} = \mathbf{1}$, if we differentiate both sides with respect to time, we get:
\begin{equation}\label{key}
	\dot{\mathbf{q}^*} \mathbf{q} +\mathbf{q}^* \dot{\mathbf{q}} = \mathbf{0},
\end{equation}
which leads to:
\begin{equation}\label{key}
	\mathbf{q}^* \dot{\mathbf{q}} = - \dot{\mathbf{q}^*} \mathbf{q} = -(\mathbf{q}^* \dot{\mathbf{q}})^*.
\end{equation}
Thus, $\mathbf{q}^* 
\dot{\mathbf{q}}$ is a pure quaternion (with zero real part). We can denote a pure quaternion as $\boldsymbol{\varpi } = 
[0, \underbrace{\boldsymbol{\omega}_1, \boldsymbol{\omega}_2, 
	\boldsymbol{\omega}_3}_{\boldsymbol{\omega}}]^\top \in \mathcal{Q}$, so we have:
\begin{equation}
	\mathbf{q}^* \dot{\mathbf{q}} = \boldsymbol{\varpi}.
\end{equation}
Multiplying both sides by $\mathbf{q}$, we get:
\begin{equation}\label{eq:2.59}
	\dot{\mathbf{q}} = \mathbf{q} \boldsymbol{\varpi}.
\end{equation}

This equation is very similar to Equation \eqref{eq:2.51}. Analogous to the case of $\mathrm{SO}(3)$, we can also discuss the instantaneous angular velocity, Lie algebra, exponential mapping, and logarithmic mapping near time $t$. When considering instantaneous changes, we can treat $\boldsymbol{\varpi}$ as a constant value, so the solution to the above differential equation is:
\begin{equation}\label{key}
	\mathbf{q}(t) = \mathbf{q}(t_0) \exp(\boldsymbol{\varpi} \Delta t),
\end{equation}
where we used the quaternion exponential mapping. Let's take a brief pause in the derivation and introduce the quaternion exponential mapping in the usual sense.

For any pure quaternion $\boldsymbol{\varpi} = [0, \boldsymbol{\omega}]^\top \in 
\mathcal{Q}$, its exponential mapping is defined as:
\begin{equation}\label{key}
	\exp \left( \boldsymbol{\varpi}  \right) = \sum\limits_{k = 0}^\infty  {\frac{1}{{k!}}{\boldsymbol{\varpi}^k}} .
\end{equation}

Separating its direction and magnitude, let $\boldsymbol{\varpi} =  \mathbf{u} \theta$, where $\theta$ is the magnitude of $\boldsymbol{\varpi}$ and $\mathbf{u}$ is the unit imaginary quaternion. Since $\mathbf{u}$ is an unit imaginary quaternion, we have:
\begin{equation}\label{key}
	\mathbf{u}^2 = -\mathbf{1}, \quad \mathbf{u}^3 = -\mathbf{u},
\end{equation}
which is similar to the self-multiplication property of unit imaginary numbers and can be used to simplify higher-order terms. Using this property, we can derive:
\begin{equation}\label{key}
	\begin{aligned}
		\exp \left( {\mathbf{u}\theta } \right) &= 1 + \mathbf{u}\theta  - \frac{1}{{2!}}{\theta ^2} - \frac{1}{{3!}}{\theta 
			^3}\mathbf{u} + \frac{1}{{4!}}{\theta ^4} +  \ldots \\
		&= \underbrace{\left( {1 - \frac{1}{{2!}}{\theta ^2} + \frac{1}{{4!}}{\theta ^4} -  \ldots } \right)}_{\cos 
			\theta} + \underbrace{\left( {\theta  - \frac{1}{{3!}}{\theta ^3} + \frac{1}{{5!}}{\theta ^5} -  \ldots } 
			\right)}_{\sin \theta}\mathbf{u} \\
		&= \cos \theta  + \mathbf{u}\sin \theta .
	\end{aligned}
\end{equation}

This formula is very similar to Euler's formula for complex numbers:
\begin{equation}\label{key}
	\exp(i \theta) = \cos \theta + i \sin \theta,
\end{equation}
and it's indeed its extension to quaternions.

Substituting the pure imaginary $\boldsymbol{\varpi}$, we obtain:
\begin{equation}\label{eq:2.66}
	\exp(\boldsymbol{\varpi}) = [\cos\theta, \mathbf{u} \sin \theta] ^\top.
\end{equation}
Also, because $\boldsymbol{\varpi}$ is an imaginary quaternion, we have:
\begin{equation}\label{key}
	\| \exp(\boldsymbol{\varpi}) \| = \cos^2 \theta + \sin^2 \theta \| \mathbf{u} \|^2 = 1.
\end{equation}
So, the result of the exponential mapping of an imaginary quaternion is a unit quaternion, which is also a mapping relationship between unit quaternions and pure quaternions. We can also think of the imaginary quaternion $\boldsymbol{\varpi}$ as a quaternion form of the Lie algebra. Therefore, an obvious question arises: what is the relationship between the quaternion form of the Lie algebra and the rotation vector form of the Lie algebra?

\subsection{Conversion between Lie Algebra of Quaternions and Rotation Vectors}
Consider a rotation matrix $\mathbf{R}$ and its rotation vector $\boldsymbol{\phi}$. Obviously, their relationship is described by the exponential mapping:
\begin{equation}
	\mathbf{R} = \mathrm{Exp} (\boldsymbol{\phi}) = \mathrm{Exp}(\theta \mathbf{n}),
\end{equation}
where $\mathbf{n}$ is the direction of the rotation vector and $\theta$ is its magnitude. We also assume that this rotation can be expressed by $\mathbf{q} = 
\mathrm{Exp} (\boldsymbol{\varpi})$, where $\boldsymbol{\varpi}$ is a pure imaginary quaternion $[0, 
\boldsymbol{\omega}]^\top$. Now let's examine the transformation relationship between these two representations.

From Equation \eqref{eq:rotationVector2Quaternion}, we know that the quaternion corresponding to $\mathbf{R}$ is:
\begin{equation}\label{key}
	\mathbf{q} = [\cos \frac{\theta}{2}, \mathbf{n} \sin \frac{\theta}{2}],
\end{equation}
By comparing with Equation \eqref{eq:2.66}, it's easy to see the relationship between $\boldsymbol{\varpi}$ and $\boldsymbol{\phi}$:
\begin{equation}\label{key}
	\boldsymbol{\varpi} = [0, \frac{1}{2} \boldsymbol{\phi}]^\top, \quad \text{or} \  
	\boldsymbol{\omega} = \frac{1}{2} \boldsymbol{\phi}.
\end{equation}

We miraculously discover that the angular velocity expressed by quaternions is exactly half of the $\mathrm{SO}(3)$ Lie algebra! This is because when using quaternions to rotate a vector, we need to multiply corresponding parts twice. Due to this ``half'' relationship, the Lie algebra corresponding to quaternions is slightly different from $\mathfrak{so}(3)$. To maintain the continuity of derivation and writing, we use a unified $\mathrm{Exp}$ relationship to combine the two definitions. In summary, for a three-dimensional instantaneous angular velocity (or the update quantity of an optimization function) $\boldsymbol{\omega} \in \mathbb{R}^3$, we define its kinematic form on $\mathrm{SO}(3)$ as:
\begin{equation}\label{eq:rotation-matrix-kinematics}
	\dot{\mathbf{R}} = \mathbf{R} \boldsymbol{\omega}^\wedge
\end{equation}
Its corresponding exponential mapping is:
\begin{equation}\label{key}
	\mathbf{R} = \mathrm{Exp} (\boldsymbol{\omega}) = \exp(\boldsymbol{\omega}^\wedge),
\end{equation}
or, if this quantity is the update amount of a pure imaginary quaternion (typically obtained from solving an optimization function), then the corresponding quaternion should only update half of it. According to the definition in Equation \eqref{eq:2.59}, the quaternion kinematic equation and exponential mapping can be written as:
\begin{equation}\label{eq:quaternion-kinematics}
	\dot{\mathbf{q}} = \frac{1}{2} \mathbf{q} [0, \boldsymbol{\omega}]^\top,
\end{equation}
which can usually be simplified as\footnote{Note that the meaning of $\boldsymbol{\omega}$ has changed here. In the previous equation, it was a three-dimensional vector, while in the next equation, it is a quaternion.}:
\begin{equation}
	\dot{\mathbf{q}} = \frac{1}{2} \mathbf{q} \boldsymbol{\omega},
\end{equation}
Here, the coefficient $1/2$ is used to unify the definition of angular velocity on $\mathrm{SO}(3)$ with quaternion angular velocity, so this equation differs from Equation \eqref{eq:2.59}. Readers should also note that this equation implies that the three-dimensional vector $\boldsymbol{\omega}$ is first converted to a quaternion before multiplying with $\mathbf{q}$, rather than directly multiplying $\mathbf{q}$ by $\boldsymbol{\omega}$.

The quaternion exponential mapping can also be written similarly as:
\begin{equation}\label{key}
	\mathbf{q} = \exp(\frac{1}{2} [0, \boldsymbol{\omega}]^\top) \buildrel \Delta \over = 
	\mathrm{Exp}(\boldsymbol{\omega}).
\end{equation}

If $\boldsymbol{\omega}$ is small, then $\cos(\frac{\theta}{2}) \approx 1, \mathbf{n} \sin \frac{\theta}{2} \approx \mathbf{n} \frac{\theta}{2}$, and the exponential mapping has a simplified form:
\begin{equation}\label{key}
	\mathrm{Exp}(\boldsymbol{\omega}) \approx [1, \frac{1}{2} \boldsymbol{\omega}],
\end{equation}

So the quaternion update formula can be simplified as\footnote{In this equation, there is no need to change the definition of $\boldsymbol{\omega}$, it is still a three-dimensional vector.}:
\begin{equation}\label{eq:2.76}
\mathbf{q} \mathrm{Exp}(\boldsymbol{\omega}) \approx \mathbf{q} [1, \frac{1}{2} \boldsymbol{\omega}],
\end{equation}

However, a significant disadvantage of this equation compared to the update equation on $\mathrm{SO}(3)$ is that the quaternion on the right-hand side is not a unit quaternion, so after long-term updates, it needs to be re-normalized \cite{Sola2017}. This problem does not exist for rotation matrices, as $\mathrm{Exp}(\boldsymbol{\omega})$ is always a rotation matrix.

Thus far, we have introduced the kinematics from the perspectives of $\mathrm{SO}(3)$ and quaternions, as well as their conversion relationship. With this relationship, we can use either rotation matrices or quaternions when writing the motion equations of a vehicle or when calculating the Jacobian matrices of optimization problems, just remember the coefficient of $1/2$. We can also mix quaternions and rotation matrices, just remember that when updating variables, quaternions only need to be updated by half.

In addition, we can also consider kinematics at the level of the Lie algebra $\mathfrak{so}(3)$. For the translation part, it can be viewed as independent three-dimensional variables or collectively considered in $\mathrm{SE}(3)$. In practice, these expressions are interchangeable without essential differences, but there may be differences in the ease of operation. We introduce several other expressions in this section, but only one of them will be detailed in subsequent chapters.

\subsection{Other Kinematic Representations}

\subsubsection{Kinematics on $\mathfrak{so}(3)$}
To give some physical meaning to mathematical symbols, we will use $\boldsymbol{\omega}$ to express angular velocity and $\boldsymbol{\phi}$ to express rotation vectors in the future. The Rodrigues formula tells us that $\mathbf{R} = \mathrm{Exp}(\boldsymbol{\phi})$. Now we want to examine the derivative of $\boldsymbol{\phi}$ with respect to time and its relationship with the instantaneous angular velocity $\boldsymbol{\omega}$.

The BCH formula gives the relationship between increments on the Lie group and the Lie algebra. Assuming that at time $t$ to $t+\Delta 
t$, $\boldsymbol{\phi}(t)$ changes to $\boldsymbol{\phi}(t) + \Delta 
\boldsymbol{\phi}$ on $\mathfrak{so}(3)$, and at the same time $\mathrm{SO}(3)$ changes from $\mathbf{R}$ to $\mathbf{R} \cdot \Delta 
\mathbf{R}$, then according to the BCH approximation, we have:
\begin{equation}\label{key}
	\Delta \mathbf{R} = \mathrm{Exp}( \mathbf{J}_r \Delta \boldsymbol{\phi}),
\end{equation}
On the $\mathrm{SO}(3)$ level, according to the definition of angular velocity, we have $\dot{\mathbf{R}} = \mathbf{R} 
\boldsymbol{\omega}^\wedge$, so:
\begin{equation}\label{key}
	\begin{array}{ll}
		\mathbf{R}\boldsymbol{\omega}^\wedge &= \dot{\mathbf{R}} = \mathop {\lim }\limits_{\Delta t \to 0} 
		\frac{{\mathbf{R}\left( {t + \Delta t} \right) - \mathbf{R}\left( t \right)}}{{\Delta t}}\\
		&\approx \mathop {\lim }\limits_{\Delta t \to 0} \frac{{\mathbf{R}\left( t \right)\mathrm{Exp}\left( 
				{{\mathbf{J}_r}\Delta \boldsymbol{\phi} } \right) - \mathbf{R}\left( t \right)}}{{\Delta t}}\\
		&\approx \mathop {\lim }\limits_{\Delta t \to 0} \frac{{\mathbf{R}\left( t \right)\left( {\mathrm{Exp}\left( 
					{{\mathbf{J}_r}\Delta \boldsymbol{\phi} } \right) - \mathbf{I}} \right)}}{{\Delta t}} = \mathbf{R} (\mathbf{J}_r \dot{\boldsymbol{\phi}})^\wedge,
	\end{array}
\end{equation}
where the last equality requires a Taylor expansion of the $\mathrm{Exp}$ function. By comparing the left and right sides, we easily obtain:
\begin{equation}
	\boldsymbol{\omega} = \mathbf{J}_r \dot{\boldsymbol{\phi}},
\end{equation}
or:
\begin{equation}\label{key}
	\dot{\boldsymbol{\phi}} = \mathbf{J}_r^{-1} \boldsymbol{\omega}.
\end{equation}
This shows the relationship between the time derivative on $\mathfrak{so}(3)$ and the instantaneous angular velocity on $\mathrm{SO}(3)$. In principle, we can also use this quantity to derive subsequent filters or optimizers. However, its physical meaning is not as intuitive as $\boldsymbol{\omega}$, so very few people actually choose this method.

\subsubsection{Kinematics on $\mathrm{SO}(3) + \mathbf{t}$}

We can incorporate linear velocity into consideration. For example, let $\mathbf{v} = \dot{\mathbf{t}}$, then the system kinematic equations can be written as:
\begin{equation}\label{key}
	\dot{\mathbf{R}} = \mathbf{R} \boldsymbol{\omega}^\wedge, \quad \dot{\mathbf{t}} = \mathbf{v}.
\end{equation}

This approach is the simplest and most intuitive, and is widely adopted.

\subsubsection{Kinematics on $\mathrm{SE}(3)$}

We can also derive kinematics on $\mathrm{SE}(3)$ and make it consistent with the exponential mapping on $\mathrm{SO}(3)$. This requires some modifications to the linear velocity part. Let the transformation matrix be:
\begin{equation}\label{key}
	\mathbf{T} = \begin{bmatrix}
		\mathbf{R} & \mathbf{t} \\
		\mathbf{0}^\top & 1
	\end{bmatrix} \in \mathrm{SE}(3),
\end{equation}
then its time derivative is:
\begin{equation}\label{key}
	\dot{\mathbf{T}} = \begin{bmatrix}
		\dot{\mathbf{R}} & \dot{\mathbf{t}} \\
		\mathbf{0}^\top & 0
	\end{bmatrix}
	= \begin{bmatrix}
		\mathbf{R} \boldsymbol{\omega}^\wedge & \mathbf{v} \\
		\mathbf{0} ^\top & 0
	\end{bmatrix}.
\end{equation}

For instance, to achieve the kinematics on $\mathrm{SE}(3)$ in the right-multiplication model, we want to obtain the form $\dot{\mathbf{T}} = \mathbf{T} \boldsymbol{\xi}^\wedge$\footnote{The $\wedge$ symbol on $\mathrm{SE}(3)$ is defined as: $\boldsymbol{\xi}^\wedge = \begin{bmatrix}
		\boldsymbol{\phi}^\wedge & \boldsymbol{\rho}^\wedge \\ \mathbf{0}^\top & 0
	\end{bmatrix} \in \mathbb{R}^{4 \times 4}$, where $\boldsymbol{\phi}$ is the rotation part and $\boldsymbol{\rho}$ is the translation part.}, let $\boldsymbol{\xi} = [\boldsymbol{\rho}, 
\boldsymbol{\phi}]^\top$, then:
\begin{equation}\label{key}
	\begin{bmatrix}
		\mathbf{R} \boldsymbol{\omega}^\wedge & \mathbf{v} \\
		\mathbf{0} ^\top & 0
	\end{bmatrix}
	= \mathbf{T} \begin{bmatrix}
		\boldsymbol{\phi}^\wedge & \boldsymbol{\rho} \\
		\mathbf{0}^\top & 0
	\end{bmatrix}.
\end{equation}

It is not difficult to derive:
\begin{equation}\label{key}
	\boldsymbol{\phi} = \boldsymbol{\omega}, \quad \boldsymbol{\rho} = \boldsymbol{R}^\top \mathbf{v}.
\end{equation}

Therefore, by defining $\boldsymbol{\xi} = [\mathbf{R}^\top \mathbf{v}, 
\boldsymbol{\omega}]^\top$, we can obtain the kinematics on $\mathrm{SE}(3)$ as:
\begin{equation}\label{key}
	\dot{\mathbf{T}} = \mathbf{T} \boldsymbol{\xi}^\wedge.
\end{equation}

\subsubsection{Kinematics on $\mathfrak{se}(3)$}

Let the Lie algebra be $\boldsymbol{\varphi}$. To derive the kinematics of $\boldsymbol{\varphi}$, we still use the approach in Section \ref{sec:so3-kinematics}. According to the BCH approximation, when $\boldsymbol{\varphi}$ increases by $\Delta \boldsymbol{\varphi}$, $\mathbf{T}$
right-multiplies $\Delta \mathbf{T}$. Analogously to the previous approach, we can write:
\begin{align}\label{key}
	\dot{\mathbf{T}} &= \mathbf{T} \boldsymbol{\xi}^\wedge = \mathop {\lim }\limits_{\Delta t \to 0} 
	\frac{{\mathbf{T}\left( t \right)\mathrm{Exp}\left( {{\mathbf{\mathcal{J}}_r}\Delta \boldsymbol{\varphi} } 
			\right) - \mathbf{T}\left( t \right)}}{{\Delta t}} \\
	& = \mathbf{T} \mathbf{\mathcal{J}}_r \dot{\boldsymbol{\varphi}}^\wedge .
\end{align}
Here, some intermediate steps are omitted. Finally, we obtain:
\begin{equation}\label{key}
	\dot{\boldsymbol{\varphi}} = \boldsymbol{\mathcal{J}}_r^{-1} \boldsymbol{\xi}.
\end{equation}
This can also be used to characterize the kinematics on the Lie algebra. However, in these expressions, only the $\mathrm{SO}(3) + \mathbf{t}$ representation corresponds to the actual physical meaning, and the other representations require some degree of transformation. In a large number of papers, researchers default to using the simplest kinematic representation, i.e., rotation plus translation. In practice, there is no need to introduce unnecessary complications in theory, so we \textbf{default to using kinematics with rotation and translation}, but the rotation representation can freely use either $\mathrm{SO}(3)$ or quaternions (corresponding to different update quantities).

\subsection{Linear Velocity and Acceleration}
Now let's consider the transformation relationship of linear velocity and acceleration between different coordinate systems. For simplicity, we consider the transformation of linear velocity and acceleration between two coordinate systems with \textbf{only rotational relationship}.

Consider coordinate systems 1 and 2. A certain vector $\mathbf{p}$ has coordinates $\mathbf{p}_1, \mathbf{p}_2$ in the two systems, and it is obvious that they satisfy the relationship $\mathbf{p}_1 = \mathbf{R}_{12} \mathbf{p}_2$, which is a simple geometric relationship.

Now we consider the case where $\mathbf{p}$ varies with time, while the two coordinate systems also undergo rotation. We want to remind the reader that \textbf{the velocity vector of $\mathbf{p}$ in the two systems is different}; it is not the expression of the same vector in different coordinate systems. Let's see why.

Taking the time derivative of the above equation, we have:
\begin{equation}\label{key}
	\begin{array}{ll}
		\dot{\mathbf{p}}_1 &= \dot{\mathbf{R}}_{12} \mathbf{p}_2 + \mathbf{R}_{12} \dot{\mathbf{p}}_2 \\
		&= \mathbf{R}_{12} \boldsymbol{\omega}^\wedge \mathbf{p}_2 + \mathbf{R}_{12}  \dot{\mathbf{p}}_2 \\
		&= \mathbf{R}_{12} (\boldsymbol{\omega}^\wedge \mathbf{p}_2 + \dot{\mathbf{p}}_2 ).
	\end{array}
\end{equation}

Traditionally, we denote $\dot{\mathbf{p}}_1 = \mathbf{v}_1, \dot{\mathbf{p}}_2 = \mathbf{v}_2$, then we can obtain the transformation equation for the two linear velocities:
\begin{equation}\label{eq:2.91}
	\mathbf{v}_1 = \mathbf{R}_{12}(\boldsymbol{\omega}^\wedge \mathbf{p}_2 + \mathbf{v}_2).
\end{equation}

We can see that there is actually a relationship between the two velocity vectors and the angular velocity. At this point, we do not speak of \textbf{different coordinate expressions of a velocity vector}, but rather \textbf{the transformation of velocity vectors in two coordinate systems}.

Continuing to take the time derivative of the above equation, we obtain:
\begin{equation}\label{key}
	\begin{array}{ll}
		\dot{\mathbf{v}}_1 &= {\dot{\mathbf{R}}_{12}}\left( {{\boldsymbol{\omega}^\wedge}{\mathbf{p}_2} + 
			{\mathbf{v}_2}} \right) + {\mathbf{R}_{12}}\left( {{{\dot{\boldsymbol{\omega}} }^\wedge}{\mathbf{p}_2} + 
			{\boldsymbol{\omega}^\wedge}{{\dot{\mathbf{p}}}_2} + {{\dot{\mathbf{v}}}_2}} \right)\\
		&= {\mathbf{R}_{12}}\left( 
		{{\boldsymbol{\omega}^\wedge}{\boldsymbol{\omega}^\wedge}{\mathbf{p}_2} + 
			{\boldsymbol{\omega}^\wedge}{\mathbf{v}_2} + {{\dot{\boldsymbol{\omega}} }^\wedge}{\mathbf{p}_2} 
			+ {\boldsymbol{\omega}^\wedge}{{\dot{\mathbf{p}}}_2} + {{\dot{\mathbf{v}}}_2}} \right)\\
		&= {\mathbf{R}_{12}}\left( {{{\dot{\mathbf{v}}}_2} + 2{\boldsymbol{\omega}^\wedge}{\mathbf{v}_2} + 
			{{\dot{\boldsymbol{\omega}} }^\wedge}{\mathbf{p}_2} + 
			{\boldsymbol{\omega}^\wedge}{\boldsymbol{\omega}^\wedge}{\mathbf{p}_2}} \right).
	\end{array}
\end{equation}

Defining $\mathbf{a}_1 = \dot{\mathbf{v}}_1, \mathbf{a}_2 = \dot{\mathbf{v}}_2$, the equation can be written as:
\begin{equation}\label{key}
	\mathbf{a}_1 = \mathbf{R}_{12} (\underbrace{\mathbf{a}_2}_{\text{acceleration}} + 
	\underbrace{2\boldsymbol{\omega}^\wedge \mathbf{v}_2}_{\text{Coriolis acceleration}} + 
	\underbrace{\dot{\boldsymbol{\omega}}^\wedge \mathbf{p}_2}_{\text{angular acceleration}} + 
	\underbrace{{\boldsymbol{\omega}^\wedge}{\boldsymbol{\omega}^\wedge}{\mathbf{p}_2}}_{\text{centripetal
			acceleration}} ).
\end{equation}

This equation gives the transformation between the expressions of acceleration in the two systems. It can be seen that due to the motion relationship between the two systems themselves, the transformation of acceleration is more complex than that of velocity, and it requires considering the angular velocity and angular acceleration between the two systems. Fortunately, these terms have special names to help readers remember. Moreover, in practical processing, since measurement sensors can only measure discrete values, in low-precision applications, we usually choose to ignore the last three terms and only retain the simplest transformation relationship.

In addition, in practical vehicles, we usually take system 1 and system 2 as the world coordinate system and the vehicle coordinate system, respectively. If we consider a moving point in the vehicle coordinate system, it is obvious that the linear velocity of this point in the vehicle system and in the world system are not the same vector, and it should be related to the rotation of the vehicle. These two linear velocities should satisfy the transformation relationship described in this section. However, we don't often talk about a moving point in the vehicle. More often, we discuss the \textbf{velocity of the vehicle itself}, which is the velocity of the vehicle body origin in the world system (the velocity of the vehicle origin in the vehicle system is always zero and has no practical meaning). This velocity is defined in the world system and is denoted as $\mathbf{v}_w$. If left-multiplied by $\mathbf{R}_{bw}$, this vector can also be transformed into the vehicle coordinate system, denoted as $\mathbf{v}_b$. We call $\mathbf{v}_b$ the \textbf{body velocity}, which essentially means the result of transforming the velocity vector in the world system into the vehicle coordinate system, and it can be measured by various sensors (such as the vehicle speed sensor, rotation sensor on the wheels, etc.). Note that this transformation relationship is different from equation \eqref{eq:2.91}, one represents the relationship between different vectors, and the other represents the coordinate transformation relationship of the same vector. Please pay attention to their differences.

\subsection{Perturbation and Jacobian Matrices}
When we left-multiply or right-multiply increments on a Lie group (whether represented by rotation matrices or quaternions), there exists a corresponding increment on the Lie algebra. Due to the existence of the Baker-Campbell-Hausdorff formula, there will be a Jacobian matrix between these two increments in the sense of first-order linear approximation. Obviously, this Jacobian matrix will differ depending on the representation method or the definition of increment addition. Below, we discuss some feasible choices and definition methods, and provide some common methods for calculating Jacobians.

If we want to differentiate functions containing rotations or transformations, this derivative can be defined either at the vector level, i.e., $\mathfrak{so}(3)$ and $\mathfrak{se}(3)$, or at the perturbation level, which means left-multiplying or right-multiplying perturbations on the original $\mathbf{R}, \mathbf{T}, \mathbf{q}$, and then differentiating with respect to the perturbation. In most cases, differentiating with respect to perturbations is a more concise and clear approach. Below, we discuss the differences in formulas when perturbing rotation matrices or quaternions separately.

\subsubsection{Example: Rotation of Vectors}
Consider a vector $\mathbf{a}$, and let's rotate it. Rotation can be expressed by either a rotation matrix $\mathbf{R}$ or a quaternion $\mathbf{q}$. Thus, the rotation of $\mathbf{a}$ can be written as $\mathbf{R}\mathbf{a}$ in the sense of matrix multiplication, or $\mathbf{q} \mathbf{a} \mathbf{q}^*$ in the sense of quaternion multiplication.

Firstly, the derivation with respect to $\mathbf{a}$ itself is trivial\footnote{That is, it can be calculated using standard matrix derivative rules without additional conversion procedures. Readers with a certain level of matrix knowledge should be able to see this on their own.}, and there is no need to elaborate\footnote{We still omit the transpose symbol at the denominator to maintain the simplicity of the formula.}:
\begin{equation}\label{key}
	\frac{{\partial \mathbf{R} \mathbf{a}}}{{\partial \mathbf{a}}} = \frac{{\partial \left( \mathbf{q} \mathbf{a} {\mathbf{q}^*} 
			\right)}}{{\partial \mathbf{a}}} = \mathbf{R}.
\end{equation}

The derivation with respect to $\mathbf{R}$ or $\mathbf{q}$ depends on the definition method. Generally, we can choose to derive with respect to the four elements of $\mathbf{q}$ itself or the Lie algebra corresponding to $\mathbf{R}$, but the Jacobian matrix corresponding to the perturbation model will be simpler. Moreover, the perturbation model is divided into left perturbation and right perturbation, and there are different definition methods for $\mathbf{R}$ and $\mathbf{q}$. Earlier in this book, the right perturbation method was used when introducing angular velocity, so here we also consider right perturbation for $\mathbf{R}$\footnote{There is no essential difference between left and right perturbation. However, the expression of velocity or acceleration quantities in different coordinate systems may differ. According to the convention described earlier in this book, we mainly use the $wb$ sequence to express the transformation relationship. In this case, the symbols for angular velocity, velocity, etc., are consistent with the measured values. To accommodate this expression method, we use the right perturbation model when deriving. If the reader still cannot understand the reason here, they can reconsider it later in the following text.}. Let the perturbation quantity be $\boldsymbol{\phi}$, then\footnote{This equation can be denoted as $\frac{{\partial \mathbf{R} \mathbf{a}}}{{\partial \mathbf{R} }}$ or $\frac{{\partial \mathbf{R} \mathbf{a}}}{{\partial \boldsymbol{\phi} }}$ on the left side.}:
\begin{equation}\label{key}
\begin{aligned}
	\frac{{\partial \mathbf{R} \mathbf{a}}}{{\partial \mathbf{R} }} &= \lim_{\boldsymbol{\phi} \to \mathbf{0}} \frac{{\mathbf{R} \mathrm{Exp} \left( \boldsymbol{\phi} \right) 
			\mathbf{a} - \mathbf{R} \mathbf{a} }}{\boldsymbol{\phi} }\\
	&= \lim_{\boldsymbol{\phi} \to \mathbf{0}} \frac{{\mathbf{R} \left( \mathbf{I} + 
			{\boldsymbol{\phi}^\wedge} \right) \mathbf{a} - \mathbf{R} \mathbf{a}}}{\boldsymbol{\phi} } = - 
	\mathbf{R} {\mathbf{a}^\wedge}.
\end{aligned}
\end{equation}

Similarly, although it is not impossible to derive with respect to the quaternion itself, it is still relatively cumbersome. Reference \cite{Sola2017} provides a method for deriving with respect to $\mathbf{q}$ without detailed derivation. Suppose $\mathbf{q} = [w, \mathbf{v}]$, then the partial derivatives with respect to the real part and the imaginary part of $\mathbf{q}$ yield:
\begin{equation}\label{key}
	\frac{\partial \mathbf{q} \mathbf{a} \mathbf{q}^*}{\partial \mathbf{q}} = 2 \left[w \mathbf{a} + \mathbf{v}^\wedge \mathbf{a}, 
	\mathbf{v}^\top \mathbf{a} \mathbf{I}_3 + \mathbf{v} \mathbf{a}^\top - \mathbf{a} \mathbf{v}^\top - 
	w\mathbf{a}^\wedge \right] \in \mathbb{R}^{3\times 4}.
\end{equation}

This is evidently too complex. However, we can perturb $\mathbf{q}$. Let the perturbation quantity be $\boldsymbol{\omega}
\in \mathbb{R}^3$, in order to be consistent with $\mathrm{SO}(3)$, we right-multiply $\mathbf{q}$ by $\frac{1}{2}[1, 
\boldsymbol{\omega}]^\top$, then, since the size of the perturbation on the rotation matrix is still the same, its Jacobian matrix should also be consistent:
\begin{equation}\label{key}
	\frac{{\partial \mathbf{R} \mathbf{a}}}{{\partial \boldsymbol{\omega} }} = - \mathbf{R} {\mathbf{a}^\wedge}.
\end{equation}
This example tells us that in practical operations, whether rotating with $\mathbf{q}$ or $\mathbf{R}$, \textbf{we can use the same Jacobian}. If the perturbation quantity is our optimization variable, then just \textbf{update accordingly} when updating the optimization variables, instead of separately deriving Jacobian matrices for the two representation methods.

\subsubsection{Example: Composition of Rotations}

Now, let's consider the composition of rotations. We want to find the derivative of $\mathrm{Log}(\mathbf{R}_1 \mathbf{R}_2)$ with respect to $\mathbf{R}_1$. We cannot directly differentiate $\mathbf{R}_1 \mathbf{R}_2$ with respect to $\mathbf{R}_1$ or $\mathbf{R}_2$ because that would involve differentiating a matrix with respect to another matrix, which is not feasible without introducing tensors. Thus, we must introduce the $\mathrm{Log}$ operator to ensure we are dealing with vector-to-vector derivatives. 

When perturbing $\mathbf{R}_1$, we can derive:
\begin{equation}\label{eq:2.99}
\begin{aligned}
	\frac{{\partial \mathrm{Log} \left( {{\mathbf{R}_1}{\mathbf{R}_2}} \right)}}{{\partial {\mathbf{R}_1}}} &= \mathop {\lim 
	}\limits_{\boldsymbol{\phi}  \to 0} \frac{{\mathrm{Log} \left( {{\mathbf{R}_1}\mathrm{Exp} \left( \boldsymbol{\phi}  \right){\mathbf{R}_2}} \right) - \mathrm{Log} \left( {{\mathbf{R}_1}{\mathbf{R}_2}} 
			\right)}}{\boldsymbol{\phi} }\\
	&= \mathop {\lim }\limits_{\boldsymbol{\phi}  \to 0} \frac{{\mathrm{Log} \left( {{\mathbf{R}_1}{\mathbf{R}_2} \mathrm{Exp}  
				\left( {\mathbf{R}_2^\top \boldsymbol{\phi} } \right)} \right) - \mathrm{Log} \left( 
			{{\mathbf{R}_1}{\mathbf{R}_2}} \right)}}{\boldsymbol{\phi} }\\
	&= \mathbf{J}_r^{ - 1}(\mathrm{Log}(\mathbf{R}_1 \mathbf{R}_2)) \mathbf{R}_2^\top.
\end{aligned}
\end{equation}
Here, the second line uses the adjoint property of $\mathrm{SO}(3)$:
\begin{equation}
\mathbf{R}^\top \mathrm{Exp} (\boldsymbol{\phi}) \mathbf{R} = \mathrm{Exp} (\mathbf{R}^\top 
\boldsymbol{\phi}),
\end{equation}
and the third line uses the first-order approximation of the Baker-Campbell-Hausdorff formula:
\begin{equation}
\begin{aligned}
	\mathrm{Log} \left( {{\mathbf{R}_1}{\mathbf{R}_2} \mathrm{Exp}  
		\left( {\mathbf{R}_2^\top \boldsymbol{\phi} } \right)} \right) &= \mathrm{Log}(\mathbf{R}_1 \mathbf{R}_2) + \mathbf{J}_r^{-1}(\mathbf{R}_1 \mathbf{R}_2) \mathrm{Log}( \mathrm{Exp}(\mathbf{R}_2^\top \boldsymbol{\phi})).
\end{aligned}
\end{equation}

Similarly, when perturbing $\mathbf{R}_2$, we can obtain:
\begin{equation}\label{eq:2.104}
	\frac{\partial \mathrm{Log} \left( {\mathbf{R}_1}{\mathbf{R}_2} \right)}{\partial {\mathbf{R}_2}} = \mathbf{J}_r^{ -1}(\mathrm{Log}(\mathbf{R}_1 \mathbf{R}_2)).
\end{equation}

Equations \eqref{eq:2.99} and \eqref{eq:2.104} serve as the basis for many complex function derivatives. It's essential for readers to grasp them. In practical applications, it's common to encounter compositions involving rotation matrices and other matrices or vectors. Many composite formulas can be derived using the above two equations.

%\section{运动学演示案例：圆周运动}
%\label{sec:motion-example}
%下面我们通过一些实际案例来演示四元数与旋转矩阵在角速度上的处理方法差异。
%
%当我们在开车时，如果把车辆控制在固定速度，方向盘打到固定角度，车辆应该就会画出一个圆周运动的轨迹。现在请考虑：这件事情如何在程序中进行模拟？
%
%显然这样一台车辆应该有固定的角速度。由于我们取\textbf{前左上}作为坐标系，该车辆的角速度矢量$\boldsymbol{\omega}$应该指向$Z$方向。而前面讲的\textbf{固定速度}，则是指在车辆坐标系中，速度矢量应该为固定指向正前方$\mathbf{v}_b=[v_x, 0, 0]^\top$。当然它在世界系下的速度必定不是沿着$X$轴方向，因为它还会同时拐弯。现在我们来实现一个模拟这种车辆运行的程序。我们会用旋转矩阵和四元数两种方法来处理车辆的旋转。
%
%\begin{lstlisting}[language=c++,caption=src/ch2/motion.cc]
%#include <gflags/gflags.h>
%#include <glog/logging.h>
%
%#include "common/eigen_types.h"
%#include "common/math_utils.h"
%#include "tools/ui/pangolin_window.h"
%
%/// 本节程序演示一个正在作圆周运动的车辆
%/// 车辆的角速度与线速度可以在flags中设置
%
%DEFINE_double(angular_velocity, 10.0, "角速度，角度制");
%DEFINE_double(linear_velocity, 5.0, "车辆前进线速度 m/s");
%DEFINE_bool(use_quaternion, false, "是否使用四元数计算");
%
%int main(int argc, char** argv) {
%	google::InitGoogleLogging(argv[0]);
%	FLAGS_stderrthreshold = google::INFO;
%	FLAGS_colorlogtostderr = true;
%	google::ParseCommandLineFlags(&argc, &argv, true);
%	
%	/// 可视化
%	sad::ui::PangolinWindow ui;
%	if (ui.Init() == false) {
%		return -1;
%	}
%	
%	double angular_velocity_rad = FLAGS_angular_velocity * sad::math::kDEG2RAD;  // 弧度制角速度
%	SE3 pose;                                                                    // TWB表示的位姿
%	Vec3d omega(0, 0, angular_velocity_rad);                                     // 角速度矢量
%	Vec3d v_body(FLAGS_linear_velocity, 0, 0);                                   // 本体系速度
%	const double dt = 0.05;                                                      // 每次更新的时间
%	
%	while (ui.ShouldQuit() == false) {
%		// 更新自身位置
%		Vec3d v_world = pose.so3() * v_body;
%		pose.translation() += v_world * dt;
%		
%		// 更新自身旋转
%		if (FLAGS_use_quaternion) {
%			Quatd q = pose.unit_quaternion() * Quatd(1, 0.5 * omega[0] * dt, 0.5 * omega[1] * dt, 0.5 * omega[2] * dt);
%			q.normalize();
%			pose.so3() = SO3(q);
%		} else {
%			pose.so3() = pose.so3() * SO3::exp(omega * dt);
%		}
%		
%		LOG(INFO) << "pose: " << pose.translation().transpose();
%		ui.UpdateNavState(sad::NavStated(0, pose, v_world));
%		
%		usleep(dt * 1e6);
%	}
%	
%	ui.Quit();
%	return 0;
%}
%\end{lstlisting}
%
%由于这是本书出现的第一个程序，我们把它贴的完整一些。后面的程序就不会这样完整了，我们只贴出核心代码。
%
%本书整体上使用GLog来管理日志，使用Gflags来管理程序参数。本程序可以接受用户指定的角速度与线速度大小，也可以指定使用旋转矩阵的处理方式还是使用四元数的处理方式。我们做了如下几件事：
%
%\begin{enumerate}
%	\item 首先，将用户给定的角速度转换为弧度制，将线速度转换到车体坐标系下的v\_body。设定仿真的时间间隔为0.05秒。
%	\item 在每次更新时，首先计算世界系下速度。为此，我们需要知道车辆的朝向，所以把pose变量的姿态取出来，右乘车体速度。
%	\item 然后再更新车辆状态。如果用户指定用四元数表示，则使用式\eqref{eq:2.76}；如果不使用四元数，则用\eqref{eq:2.53}更新自身姿态。
%	\item 最后将计算好的姿态交给UI显示，并等待一个时间间隔。
%\end{enumerate}
%
%为了实时显示本节程序效果，我们为读者准备了一个UI界面。如果往UI界面中更新当前的位姿与速度，它们就会实时显示在一个3D窗口中，如图~\ref{fig:motion-example}~所示。在编译本章程序后，读者可以运行：
%\begin{lstlisting}[language=sh,caption=终端输入：]
%./bin/motion
%\end{lstlisting}
%来执行本节程序。如果需要改变参数或计算方式，填写它的gflags即可：
%\begin{lstlisting}[language=sh,caption=终端输入：]
%bin/motion --use_quaternion=true --angular_velocity=15
%\end{lstlisting}
%
%\begin{figure}[!htp]
%	\centering
%	\includegraphics[width=0.7\textwidth]{math-basics/motion-example.png}
%	\caption{一个圆周运动车辆的运动学模拟}
%	\label{fig:motion-example}
%\end{figure}
%
%本书后文的大部分程序都可以通过这种方式执行。读者可以用本节程序来适应一下本书的代码风格。通过本节实验，我们可以看到车辆走出一个完整的圆形轨迹，它的世界系速度类似于三角函数，本体系下速度则保持$X$轴固定不变。使用四元数还是旋转矩阵，在处理运动学方面并无本质差异。读者可以利用本节程序，演示一些常见的自由落体或者抛物线运动。这些作为本节习题留给读者。
%
%\section{滤波器与最优化理论}
%下面我们回顾基础的滤波器原理以及它和最优化方法之间的联系。我们仍然从状态估计讲起。
%
%\subsection{状态估计问题与最小二乘}
%SLAM问题、定位问题或者建图问题都可以概括为状态估计问题。典型的离散时间状态估计问题由一
%组运动方程和一组观测方程组成：
%\begin{equation}
%	\left\{ \begin{array}{l}
%		{\mathbf{x}_k} = \mathbf{f}\left( {{\mathbf{x}_{k - 1}},{\mathbf{u}_k}} \right) + \mathbf{w}_k,\quad k=1, \ldots, N\\
%		{\mathbf{z}_{k}} = \mathbf{h} \left( \mathbf{x}_k  \right)+ \mathbf{v}_{k},
%	\end{array} \right.
%\end{equation}
%其中$\mathbf{f}$称为运动方程，$\mathbf{h}$称为观测方程，$\mathbf{w}_k \sim \mathcal{N}(\mathbf{0}, \mathbf{R}_k)$, $\mathbf{v}_k 
%\sim \mathcal{N}( \mathbf{0}, \mathbf{Q}_k)$为高斯分布的随机噪声。如果设$\mathbf{f}$和$\mathbf{h}$为线性函数，就可以得到线性高斯系统（linear Gaussian, LG系统）的状态估计问题：
%\begin{equation}
%	\left\{ \begin{array}{l}
%		{\mathbf{x}_k} = \mathbf{A}_k {{\mathbf{x}_{k - 1}}+{\mathbf{u}_k}} + \mathbf{w}_k \\
%		{\mathbf{z}_{k}} = \mathbf{C}_k  { \mathbf{x}_k} + \mathbf{v}_{k} \end{array} \right. .
%\end{equation}
%其中$\mathbf{A}_k, \mathbf{C}_k$为系统的转移矩阵和观测矩阵。线性系统是最简单的状态估计问题，它的
%无偏最优估计由\textbf{卡尔曼滤波器}（Kalman filter, KF）给出\cite{Zarchan2005,Barfoot2016}。
%
%\subsection{卡尔曼滤波器}
%卡尔曼滤波器描述了如何从一个时刻的状态估计递推到下一个时刻。它由\textbf{预测}（prediction）和\textbf{更新}（update）两个步骤组成。预测步骤对运动方程进行递推，观测步骤则对上一步结果进行修正。我们设$k-1$时刻状态估计为$\mathbf{x}_{k-1},
% \mathbf{P}_{k-1}$，其中$\mathbf{x}_{k-1}$为均值，$\mathbf{P}_{k-1}$为估计协方差矩阵。
%\begin{mdframed}
%	\begin{enumerate}
%		\item 预测：
%		\begin{equation}
%			\mathbf{x}_{k,\mathrm{pred}} = {\mathbf{A}_k {\mathbf{x}_{k - 1}} + {\mathbf{u}_k}}, \quad 
%			\mathbf{P}_{k,\mathrm{pred}} = \mathbf{A}_k \mathbf{P}_{k-1} \mathbf{A}^\top_k + \mathbf{R}_k.
%		\end{equation}
%		\item 更新：
%		先计算$\mathbf{K}$，它又称为\textbf{卡尔曼增益}。
%		\begin{equation}
%			\label{eq:kalman-K-another}
%			\mathbf{K}_k = \mathbf{P}_{k, \mathrm{pred}} \mathbf{C}_k^\top {\left( {\mathbf{C}_k \mathbf{P}_{k, 
%			\mathrm{pred}} \mathbf{C}_k^\top + {\mathbf{Q}_k}} \right)^{ - 1}}.
%		\end{equation}
%		然后计算后验概率的分布。
%		\begin{equation}
%			\begin{array}{l}
%				{\mathbf{x}}_k = {\mathbf{x}_{k, \mathrm{pred}}} + \mathbf{K}_k \left( {\mathbf{z}_k - 
%				{\mathbf{C}_k}{\mathbf{x}_{k, \mathrm{pred}}}} \right), \\
%				\mathbf{P}_k = \left( {\mathbf{I} - \mathbf{K}_k {\mathbf{C}_k}} \right) \mathbf{P}_{k, \mathrm{pred}}.
%			\end{array}
%		\end{equation}
%	\end{enumerate}
%\end{mdframed}
%
%其中下标$\text{pred}$表示预测得到的结果。不同书籍可能会使用各种不同的符号来表达它和最终估计值的差异，比如$\hat{\mathbf{x}}, \mathbf{x}^*, \check{\mathbf{x}}$，等等。本书后文统一使用下标方式来区分预测变量。
%
%我们不准备展开线性卡尔曼滤波器的推导过程。但我们要提醒读者，在线性系统中，各类方法（贝叶斯滤波、卡尔曼滤波、最小二乘、增益最优化等）都会达成同样的结论，“条条大路通罗马”，所以卡尔曼滤波器可以由各种方法推导出来，例如：
%\begin{enumerate}
%	\item 从增益最优化角度来推导，即，假设最优估计由$\mathbf{x}_{k, \mathrm{pred}} +\mathbf{K}_k (\mathbf{z}_k - \mathbf{C}_k \mathbf{x}_{k, \mathrm{pred}})$形式构成，然后寻找最优的$\mathbf{K}_k$。这种推导方式最为简单，也是大多数
%	类似材料的首选推导方法。
%	\item 从贝叶斯滤波器来推导，这需要用到高斯分布的线性变换和边缘化。这也是\cite{Thrun2005}
%	的首选做法，也是我们在《十四讲》中的做法。
%	\item 从最大后验估计（MAP）来推导，这种方法只需要基础的线性代数即可。 
%	\item 
%	从批量MAP解出发，使用Cholesky分解区分前后向过程，由前向过程推导卡尔曼滤波。这是\cite{Barfoot2016}
%	的首选做法，优点是可以很好地显示卡尔曼滤波器与Rauch-Tung-Stribel Smoother（RTS平滑）方法的联系（
%	以及与批量MAP间的联系），缺点是推导过程比较复杂，需要大量的篇幅。
%\end{enumerate}
%
%与传统卡尔曼滤波器不同的是，本书会统一使用李群李代数的方式来处理卡尔曼滤波器。因为我们需要考虑运动学方程，所以状态变量$\mathbf{x}$除了含有位置和姿态以外，还会带有速度、传感器零偏等其他变量。这样一个高维的$\mathbf{x}$就落在一个高维流形$\mathcal{M}$上，称为\textbf{流形上的卡尔曼滤波器}（KF on manifold）\cite{he2021kalman}。在下一章我们会看到，这种流形的处理方式要比基于欧拉角或者四元数原始分量的方式更加简洁。
%
%\subsection{非线性系统的处理方法}
%在非线性系统中，首选的方式是对$\mathbf{f}$和$\mathbf{h}$进行\textbf{线性化}（linearization）。线性化本质是求一个函数在固定点的\textbf{泰勒展开}（Taylor expansion），并保留一阶系数。线性化是后文广泛用到的理论。如果对一个普通的矢量函数$\mathbf{f}(\mathbf{x})$在$\mathbf{x}_0$点处进行线性化，应该得到：
%\begin{equation}\label{key}
%\mathbf{f} (\mathbf{x}_0 + \Delta \mathbf{x}) = \mathbf{f} (\mathbf{x}_0) + \mathbf{J} \Delta \mathbf{x} + \frac{1}{2} \Delta \mathbf{x} ^\top \mathbf{H} \Delta \mathbf{x} + O(\Delta \mathbf{x}^2),
%\end{equation}
%这里$\mathbf{J}$称为\textbf{雅可比矩阵}（Jacobians），$\mathbf{H}$称为\textbf{海塞矩阵}（Hessians），是线性化中最重要的两个矩阵。如果只保留一阶项，那么$\mathbf{f}(\mathbf{x})$就可以近似为：
%\begin{equation}\label{key}
%\mathbf{f} (\mathbf{x}_0 + \Delta \mathbf{x}) \approx \mathbf{f} (\mathbf{x}_0) + \mathbf{J} \Delta \mathbf{x},
%\end{equation}
%
%我们可以对非线性系统的运动方程和观测方程进行线性化，然后将卡尔曼滤波器的结论应用在非线性系统中，得到\textbf{扩展卡尔曼滤波器}（Extended Kalman filter, EKF）。如果不展开讨论$\mathbf{x}$的定义以及各矩阵的详细形式，通用的EKF可以简单描述如下。
%
%首先，将运动方程在上一时刻的状态进行线性化，得到：
%\begin{equation}\label{key}
%\mathbf{x}_k \approx \mathbf{f}(\mathbf{x}_{k-1}, \mathbf{u}_k) + \mathbf{F}_k \Delta \mathbf{x}_k + \mathbf{w}_k,
%\end{equation}
%这里$\mathbf{F}$即为运动方程的相对于上一时刻状态的雅可比矩阵。该矩阵主要用于计算协方差的预测值。至于均值的预测值，可以将$\mathbf{x}_{k-1}$代入$\mathbf{f}$后得到。这样就写出了EKF的预测过程：
%\begin{mdframed}
%\begin{equation}\label{key}
%\mathbf{x}_{k, \text{pred}} = \mathbf{f}(\mathbf{x}_{k-1}, \mathbf{u}_k), \quad \mathbf{P}_{k, \text{pred}} = \mathbf{F}_k \mathbf{P}_{k-1} \mathbf{F}_k^\top + \mathbf{R}_k.
%\end{equation}
%\end{mdframed}
%注意这里实际上假设了\textbf{一个高斯分布状态变量经过非线性函数后仍为高斯分布}。这其实是一个近似，与实际情况可能差别较大。对于观测方程，可以在$\mathbf{x}_{k, \text{pred}}$处作线性化，得到：
%\begin{equation}\label{key}
%\mathbf{z}_k \approx \mathbf{h}(\mathbf{x}_{k, \text{pred}}) + \mathbf{H}_k (\mathbf{x}_k - \mathbf{x}_{k, \text{pred}}) + \mathbf{n}_k,
%\end{equation}
%然后代入卡尔曼滤波器的增益公式和更新方程，就可以得到EKF的更新过程：
%\begin{mdframed}
%\begin{align}\label{key}
%\mathbf{K}_k &= \mathbf{P}_{k, \text{pred}} \mathbf{H}_k^\top (\mathbf{H}_k \mathbf{P}_{k, \text{pred}} \mathbf{H}_k^\top + \mathbf{Q}_k)^{-1}, \\
%\mathbf{x}_k &= \mathbf{x}_{k, \text{pred}} + \mathbf{K}_k (\mathbf{z}_k - \mathbf{H}_k \mathbf{x}_{k, \text{pred}}), \\
%\mathbf{P}_k &= (\mathbf{I} - \mathbf{K}_k \mathbf{C}_k) \mathbf{P}_{k, \text{pred}}.
%\end{align}
%\end{mdframed}
%
%对比KF和EKF，我们发现它们在公式上基本是一样的，只是EKF几个系数矩阵并不固定，可以随着线性化点发生改变而已。
%
%这样我们就快速地回顾了一遍KF和EKF的公式，但这里的讨论并没有展开说明，当$\mathbf{x}$中存在位移、旋转、速度等变量时，每个矩阵应该怎样计算。特别地，如果$\mathbf{x}$当中的旋转以$\mathbf{R}$的形式来表示，我们实际并不能直接写$\mathbf{x}_k - \mathbf{x}_{k-1}$或者$\mathbf{x}_k - \mathbf{x}_{k, \text{pred}}$这样的写法，而应该使用左右扰动模型来处理这些项。当引入李群李代数之后，EKF应该作出怎样的改变，是我们在第~\ref{cpt:ins}~章中要讨论的问题。
%
%\subsection{最优化方法与图优化}
%另一方面，运动学方程和观测方程都可以看成一个状态变量$\mathbf{x}$与运动学输入、观测值之间的残差，这是一种\textbf{批量最小二乘}（batch least square）的视角：
%\begin{align}\label{eq:2.118}
%\mathbf{e}_{\text{motion}} &= \mathbf{x}_k - \mathbf{f}(\mathbf{x}_{k-1}, \mathbf{u}) \sim \mathcal{N}(\mathbf{0}, \mathbf{R}_k), \\
%\mathbf{e}_{\text{obs}} &= \mathbf{z}_k - \mathbf{h}(\mathbf{x}_k) \sim \mathcal{N}(\mathbf{0}, \mathbf{Q}_k).
%\end{align}
%
%而滤波器当中的最优状态估计可以看成关于各误差项的最小二乘问题：
%\begin{equation}\label{key}
%\mathbf{x}^* = \arg \min_{\mathbf{x}}  \sum_{k} \left( \mathbf{e}_k^\top \boldsymbol{\Omega}_k^{-1} \mathbf{e}_k \right).
%\end{equation}
%其中$\mathbf{e}_k$表示第$k$项误差，$\boldsymbol{\Omega}_k$为该误差的协方差矩阵。这里$\mathbf{e}_k$可以由前面的运动误差或观测误差代入，但最小二乘算法并不刻意区分运动学误差或观测误差。对于一个通用的误差函数$\mathbf{e}_k$组成的最小二乘问题，我们可以用\textbf{迭代最优化}方法进行求解。它们的整体思路是这样的：
%
%\begin{enumerate}
%\item 首先，从$\mathbf{x}$的某个初始值出发，例如$\mathbf{x}_0$。
%\item 设第$i$次的迭代值为$\mathbf{x}_i$，那么对上述误差函数，在$\mathbf{x}_i$处进行线性化，得到：
%\begin{equation}\label{key}
%\mathbf{e}_k(\mathbf{x}_i + \Delta \mathbf{x}) \approx \mathbf{e}_k (\mathbf{x}_i) + \mathbf{J}_{k,i} \Delta \mathbf{x}_i ,
%\end{equation}
%这里线性化矩阵为$\mathbf{J}_{k,i}$。
%\item 利用高斯牛顿法或者类似的求解方法，解得本次迭代的增量$\Delta \mathbf{x}_i$。以高斯牛顿法为例，其求解的线性方程为：
%\begin{equation}\label{key}
%\sum_k (\mathbf{J}_{k,i} \boldsymbol{\Omega}_k^{-1} \mathbf{J}_{k,i}^\top) \Delta \mathbf{x}_i = - \sum_k (\mathbf{J}_{k,i} \boldsymbol{\Omega}_k^{-1} \mathbf{e}_k).
%\end{equation}
%\item 更新$\mathbf{x}_i$，得到下次迭代值：$\mathbf{x}_{i+1} = \mathbf{x}_i + \Delta \mathbf{x}_i$。
%\item 判断算法是否收敛。若收敛则退出，不收敛则进行下一次迭代。
%\end{enumerate}
%
%最优化方法与滤波器方法有千丝万缕的联系。它们在线性系统中会得到同样的结果\cite{Barfoot2016}，但在非线性系统中通常不然。主要原因有以下几个：
%\begin{enumerate}
%	\item 最优化方法有迭代过程，而EKF则没有。
%	\item 迭代过程会不断在新的线性化点$\mathbf{x}_i$上求取雅可比矩阵，而EKF的雅可比矩阵只在预测位置上求取一次。
%	\item EKF还会区分$\mathbf{x}_{k,\mathrm{pred}}$，分开处理预测过程与观测过程。而最优化方法则没有$\mathbf{x}_{k,\mathrm{pred}}$，统一处理各处的状态变量。
%\end{enumerate}
%
%一个重要的问题是，如果我们忽略上述第3条，将卡尔曼滤波器看作非线性优化，那么卡尔曼滤波器应该有几个优化变量和几种误差函数？答案是：两个优化变量，三种误差函数。两个优化变量是指$\mathbf{x}_{k-1}$和$\mathbf{x}_{k}$，而三种误差函数分别是：
%\begin{enumerate}
%\item $k-1$时刻的状态$\mathbf{x}_{k-1}$服从它的先验高斯分布。我们设$\mathbf{x}_{k-1} \sim \mathcal{N}(\bar{\mathbf{x}}_{k-1}, \mathbf{P}_{k-1})$\footnote{注意这里必须引入$\bar{\mathbf{x}}_{k-1}$，它是一个已知的数值，在上一时刻算得。而$\mathbf{x}_{k-1}$是一个可变化的变量，请注意区分。}，那么此处产生了一个\textbf{先验误差}：
%\begin{equation}\label{key}
%\mathbf{e}_{\text{prior}} = \mathbf{x}_{k-1} - \bar{\mathbf{x}}_{k-1} \sim \mathcal{N}(0, \mathbf{P}_{k-1}).
%\end{equation}
%\item 从$k-1$到$k$的\textbf{运动误差}；
%\item $k$时刻的\textbf{观测误差}。
%\end{enumerate}
%后两者已经列写在式\eqref{eq:2.118}中。这样，卡尔曼滤波器与最优化问题就等效了起来（见图~\ref{fig:ekf-factors}）。当然它们实际求解过程是有差异的。EKF并不会更新$\mathbf{x}_{k-1}$，只计算$\mathbf{x}_k$的变化量，而最优化则一视同仁。另一方面，EKF也会更新协方差矩阵$\mathbf{P}_{k}$，而普通的优化器只计算均值部分$\mathbf{x}_{k}$。如果我们想得到$\mathbf{P}_{k}$，还需要对最优化问题进行\textbf{边缘化}（Marginalization）。
%
%\begin{figure}[!htp]
%	\centering
%	\includegraphics[width=0.7\textwidth]{math-basics/ekf-factors.pdf}
%	\caption{卡尔曼滤波器与图优化模型}
%	\label{fig:ekf-factors}
%\end{figure}
%
%在SLAM领域，最优化问题通过用图模型进行描述，对应的图模型称为\textbf{图优化}（graph optimization）或者\textbf{因子图}(factor graph)。因子图模型可以进一步引入\textbf{概率图模型}中的方法进行求解。本书不刻意区分图优化和因子图的概念，它们在实际操作当中通常没有太大区别。但是，将卡尔曼滤波器与图优化方法进行对比和讨论，是本书后文的重点之一。我们会实际来实现一遍经典的EKF和图优化方法，来求解带有惯导、GPS和激光点云的问题。我们也会将EKF拓展成迭代卡尔曼滤波器（IEKF），来处理观测模型中存在最近邻问题的情况（带有最近邻问题的观测模型，方程数量和形式可能在迭代过程中发生改变，而非简单地在不同点进行线性化）。
%
%\section{小结}
%本节向读者介绍了常见的各种坐标系、运动学理论，重点介绍了四元数与$\mathrm{SO}(3)$两种处理运动学的方法，并讨论了它们的异同。我们也回顾了KF、EKF的基本公式，讨论了它们和图优化之间的一些差异。
%
%本节内容以回顾为主，下一节我们将展开介绍ESKF，并给出实现以及动画演示。
%
%\section*{习题}
%\begin{enumerate}
%	\item 分别使用左右扰动模型，计算 $$\frac{\partial \mathbf{R}^{-1} \mathbf{p}}{\partial \mathbf{R}}.$$
%	\item 分别使用左右扰动模型，计算 $$\frac{\partial \mathbf{R}_1 \mathbf{R}_2^{-1}}{\partial \mathbf{R}_2}.$$
%	\item 将\ref{sec:motion-example}节的实验修改成带旋转的抛物线运动。物体一方面沿Z轴自转，一方面存在水平的初始线速度，又受到$-Z$方向的重力加速度影响。请设计程序并完成动画演示。
%\end{enumerate}

\newpage